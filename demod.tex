\documentclass[preprint]{sigplanconf}

% The following \documentclass options may be useful:
%
% 10pt          To set in 10-point type instead of 9-point.
% 11pt          To set in 11-point type instead of 9-point.
% authoryear    To obtain author/year citation style instead of numeric.

\usepackage{amsmath}
\usepackage{slatex}

\begin{document}

\conferenceinfo{PLDI '13}{16 June 2013, Seattle, Washington, USA.} 
\copyrightyear{2013} 
\copyrightdata{[to be supplied]} 

\titlebanner{banner above paper title}        % These are ignored unless
\preprintfooter{short description of paper}   % 'preprint' option specified.

\title{Enabling Optimizations through Demodularization} 

\authorinfo{Blake Johnson}
           {Brigham Young University}
           {blake.johnson@byu.edu}
\authorinfo{Jay McCarthy}
           {Brigham Young University}
           {jay@cs.byu.edu}

\maketitle

\begin{abstract}
Programmers want to write modular programs to increase maintainability and create abstractions, but modularity hampers optimizations, especially when modules are compiled separately or written in different languages. 
In languages with syntactic extension capabilities, each module in a program can be written in a separate language, and the module system must ensure that the modules interoperate correctly. 
In Racket, the module system ensures this by separating module code into phases for runtime and compile-time and allowing phased imports and exports inside modules. 
We present an algorithm, called demodularization, that combines all executable code from a phased modular program into a single module that can then be optimized as a whole program. 
The demodularized programs have the same behavior as their modular counterparts but are easier to optimize. 
We show that programs maintain their meaning through an operational semantics of the demodularization process and verify that performance increases by running the algorithm and existing optimizations on Racket programs.
\end{abstract}

\category{CR-number}{subcategory}{third-level}

\terms
term1, term2

\keywords
keyword1, keyword2

\section{Introduction}

Programmers should not have to sacrifice the software engineering goals of modular design and good abstractions for performance. 
Instead, their tools should make running a well-designed program as efficient as possible. 
Many languages provide features for creating modular programs, which enable separate compilation and module reuse.
Some languages provide expressive macro systems, which enable programmers to extend the compiler in arbitrary ways.
Combining module systems with expressive macro systems allow programmers to write modular programs with each module written in its own domain-specific language.
A compiler for such a language must ensure that modular programs have the same meaning no matter the order in which the modules are compiled.
A phased module system, like the one described by Flatt () for Racket, is a way to allow both separately compiled modules and expressive macros in a language.

Modular programs are difficult to optimize because the compiler has little to no information about values that come from other modules when compiling a single module.
Existing optimizations have even less information when modules can extend the compiler. 
Good abstractions are meant to obscure internal implementations so that it is easier for programmers to reason about their programs, but this obscurity also limits information available for optimizations.  
In contrast, non-modular programs are simpler to optimize because the compiler has information about every value in the program.

Some languages avoid the problem of optimizing modular programs by not allowing modules, while others do optimizations at link time, and others use inlining. 
Not allowing modules defeats the benefits of modular design. 
Link time optimizations can be too low level to do useful optimizations. 
Inlining must be heuristic-based, and good heuristics are hard to develop. 

Our solution for optimizing modular programs, called demodularization, is to transform a modular program into a non-modular program by combining all runtime code and data in the program into a single module.
In a phased module system, finding all of the runtime values is not trivial.
Phased module systems allow programmers to refer to the same module while writing compiler extensions and while writing normal programs.
A demodularized program does not need to include modules that are only needed during compile-time, but whether or not the module is needed only at compile-time is not obvious from just examining the module in isolation. 

A program with a single module is effectively a non-modular program. After demodularization, a program becomes a single module, so existing optimizations have more information to work with. Also, it enables new optimizations that need whole program information. 

We provide an operational semantics for a simple language with a phased module system, and show that the demodularization process preserves program meaning. We also provide an implementation of demodularization for the Racket programming language, and verify experimentally that programs perform better after demodularization.

We use the operational semantics model of the demodularization process to explain why demodularization is correct, then describe an actual implementation for Racket, followed by experimental results of demodularizing and optimizing real-world Racket programs. The operational semantics model removes the unnecessary details of the full implementation so the demodularization process is easier to understand and verify. The actual implementation presents interesting difficulties that the model does not. The experimental results show that demodularization improves performance, especially when a program is highly modular. 

\section{Intuition}

The Racket program in Figure~\ref{main-rkt} is the main module of a program that uses a queue library. 
In order to understand how this program would be demodularized, we first need to understand how it is evaluated by the Racket runtime.

\begin{figure}[h]
\begin{schemedisplay}
#lang racket/base
(require "queue.rkt")

(with-queue (1 2 3 4 5 6)
  (enqueue 4)
  (displayln (dequeue))
  (displayln (dequeue)))
\end{schemedisplay}
\caption{\texttt{main.rkt}}
\label{main-rkt}
\end{figure}

The first thing that the Racket runtime does to a program is compile it to bytecode. 
Because Racket allows extensions to the compiler in the form of macros, while a module is being compiled, it also expands any uses of macros in the programs.
The program in Figure~\ref{main-rkt} uses a macro called \scheme{with-queue}. 
The \scheme{with-queue} macro is defined in \texttt{queue.rkt} in Figure~\ref{queue-rkt}.

\begin{figure}[h]
\begin{schemedisplay}
#lang racket/base
(require (for-syntax racket/base
                     racket/syntax)
         "short-queue.rkt"
         "long-queue.rkt")

(define-syntax (with-queue stx)
  (syntax-case stx ()
    [(with-queue (v ...) e ...)
     (begin
       (define type 
         (if (> (length (syntax->list #'(v ...))) 5) 
	     'long 
             'short))
       (define make-queue 
         (format-id #'stx "make-~a-queue" type))
       (define enqueue (format-id #'stx "~a-enqueue" type))
       (define dequeue (format-id #'stx "~a-dequeue" type))
       #`(let ([q (#,make-queue v ...)])
           (define (#,(datum->syntax stx 'dequeue)) 
             (#,dequeue q))
           (define (#,(datum->syntax stx 'enqueue) x)
             (#,enqueue q x))
           e ...))]))

(provide with-queue)
\end{schemedisplay}
\caption{\texttt{queue.rkt}}
\label{queue-rkt}
\end{figure}

This macro creates bindings for \scheme{enqueue} and \scheme{dequeue} inside of a \scheme{with-queue} block and chooses whether to use a long or short queue implementation based on the initial size of the queue.
The implementations for the long and short queues are also in separate modules. 
For the purposes of this example, the long queues are implemented with vectors and the short queues are implemented with lists, as seen in Figures~\ref{long-queue-rkt} and \ref{short-queue-rkt}.

\begin{figure}[h]
\begin{schemedisplay}
#lang racket/base
(define (make-long-queue . vs)
  .... make-vector ....)

(define (long-enqueue q v)
  .... vector-set! ....)

(define (long-dequeue q)
  .... vector-ref ....)

(provide (all-defined-out))
\end{schemedisplay}
\caption{\texttt{long-queue.rkt}}
\label{long-queue-rkt}
\end{figure}

\begin{figure}[h]
\begin{schemedisplay}
#lang racket/base
(define (make-short-queue . vs)
  .... list ....)

(define (short-enqueue q v)
  .... cons ....)

(define (short-dequeue q)
  .... list-ref ....)

(provide (all-defined-out))
\end{schemedisplay}
\caption{\texttt{short-queue.rkt}}
\label{short-queue-rkt}
\end{figure}

All four of these modules together make up the whole program.
When compilation encounters a \scheme{require} expression, it compiles the required module so that any bindings the required module provides can be used in compiling the current module.
In this example, the Racket runtime begins compiling \texttt{main.rkt}, then hits the \scheme{require} expression for \texttt{queue.rkt} and compiles it, which in turn triggers compiliation of \texttt{short-queue.rkt} and \texttt{long-queue.rkt}. 
After compiling the queue implementations, the compiler finishes compiling \texttt{queue.rkt} so that the \scheme{with-queue} macro is ready for use.
When the compiler encounters the call to \scheme{with-queue} in \texttt{main.rkt}, it uses the version it just compiled to transform the syntax of \texttt{main.rkt} into the code in Figure~\ref{main-rkt-expanded}.

\begin{figure}[h]
\begin{schemedisplay}
(module main racket/base
  (#%module-begin
   (require "queue.rkt")
   (let ((q (make-long-queue 1 2 3 4 5 6)))
     (define (dequeue) (long-dequeue q))
     (define (enqueue x) (long-enqueue q x))
     (enqueue 4)
     (displayln (dequeue))
     (displayln (dequeue)))))
\end{schemedisplay}
\caption{\texttt{main.rkt} expanded}
\label{main-rkt-expanded}
\end{figure}

Because there were more than five initial values, the macro expanded into a use of the long-queue implementation.
Notice that although this macro is intended to be an optimization by choosing the correct data structure implementation, there are still optimizations that cannot be made because of the module boundary between the implementation and uses of the \scheme{long-queue} functions.
The runtime finishes by turning the expanded code into bytecode and then evaluating the bytecode.
Evaluation begins with the main module's bytecode, and also traces requires to evaluate any runtime code in each required module.
In this example, the runtime would follow the \scheme{require} for \texttt{queue.rkt} and then follow the \scheme{require} for each queue implementation. 
The queue implementations would install definitions for each of their provided functions, then the body of \texttt{main.rkt} would run.

The main idea behind demodularization is to run the same code that would be run in this evaluation process, but put it all into a single module.
For a program like the one in Figure~\ref{main-rkt}, this would entail placing all of the expanded code of each module into a single module, which would look like Figure~\ref{main-demod-rkt}.

\begin{figure}[h]
\begin{schemedisplay}
(module main racket/base
  (#%module-begin
   (define (make-short-queue . vs)
    .... list ....)

   (define (short-enqueue q v)
    .... cons ....)

   (define (short-dequeue q)
    .... list-ref ....)

   (define (make-long-queue . vs)
    .... make-vector ....)

   (define (long-enqueue q v)
    .... vector-set! ....)

   (define (long-dequeue q)
    .... vector-ref ....)

   (let ((q (make-long-queue 1 2 3 4 5 6)))
     (define (dequeue) (long-dequeue q))
     (define (enqueue x) (long-enqueue q x))
     (enqueue 4)
     (displayln (dequeue))
     (displayln (dequeue)))))
\end{schemedisplay}
\caption{\texttt{main.rkt} demodularized}
\label{main-demod-rkt}
\end{figure}

Notice that we do not include the code from \texttt{queue.rkt} because it is only used during compile-time.
The phased module system of Racket separates runtime and compile-time into numbered phases, starting at phase 0.
Compile-time code is phase 1, and can only use code available at phase 1. 
This is the reason for the \scheme{for-syntax} \scheme{require} expressions in Figure~\ref{queue-rkt}. 
Although the module has access to \scheme{racket/base} bindings at phase 0, it doesn't have access to those bindings at phase 1, which is the phase that the body of the \scheme{with-queue} macro is evaulated in.
Macros are special because they provide a link between two phases. 
The binding is available at phase 0, but the code is written in phase 1.
This phase separation allows macros and code to coexist across multiple modules and still be compiled separately and deterministically.
Also, macro implementations can use macros, creating phases higher than 1, and the templates inside macros can refer to code in negative phases.
When tracing \scheme{require} expressions to find code to include in the demodularized program, we only need to include phase 0 code.
Because modules can be required at a phase relative to the current module, discovering phase 0 code must also take this phase shifting into account.
The redex model will go into more detail about how the phased imports and exports impact the demodularization process.

The program in Figure~\ref{main-demod-rkt} is in a single module and when evaluated will run the same code as before demodularization, except for module loading.
While this is a slight improvement in performace, we lose the benefit of separate compilation.
The real benefit is now the program can be optimized much more aggressively now that all of the information about the program is in one place.
Figure~\ref{main-demod-opt-rkt} shows what the program looks like after optimization.

\begin{figure}[h]
\begin{schemedisplay}
(module main racket/base
  (#%module-begin
   (let ((q (.... make-vector .... 1 2 3 4 5 6 ....)))
     (.... vector-set .... 4 ....)
     (displayln (.... vector-ref ....))
     (displayln (.... vector-ref ....)))))
\end{schemedisplay}
\caption{\texttt{main.rkt} demodularized and optimized}
\label{main-demod-opt-rkt}
\end{figure}

Notice that now all of the \scheme{long-queue} operations can be inlined and we don't need the definitions anymore.
Also, the \scheme{short-queue} definitions can be eliminated because they are never used in the program.
Finally, because all the information about the queue is known, this program could be optimized into just printing out the final answers because the program is deterministic.
Demodularizing a program like \texttt{main.rkt} allows for optimizations that cannot be performed when the program is separated into modules.


\section{Model}

Grammar.

Sample program.

Compiled version.

Evaluation of program.

Demodularization of program.

Evaluation of demodularized program.

Argue that the evaluations are the same.

\section{Implementation}

The demodularization algorithm for the Racket module system operates on Racket bytecode. 
Racket's bytecode format is one step removed from the fully-expanded kernel language: instead of identifiers for bindings, it uses locations.
For toplevel bindings, these locations point to memory allocated for each module known as the module's prefix.
So, in Figure XXX, foo would be in prefix location 0 and bar would be in prefix location 1, and all the references to foo and bar are replaced with references to 0 and 1.
Like in the model, the algorithm combines all phase 0 code into a single module, but since the references are locations instead of identifiers, the locations of different modules overlap.
We solve this by extending the prefix of the main module to have locations for the required module's toplevel identifiers, and then adjusting the toplevel references in the required module to those new locations. 

After combining all the code for a program into a single module, we want to optimize it.
The existing optimizations for Racket operate on an intermediate form that is part way between fully-expanded code and bytecode. 
Therefore, to hook into the existing optimizations, we decompile the bytecode of the demodularized program into the intermediate form and then run it through the optimizer to produce bytecode once more.

\section{Evaluation}
   \begin{enumerate} 
   \item What is to be measured?
   
   Performance of modular programs and demodularized programs.
  
   \item How is it to be evaluated?
   
   Speed, program size, and memory usage. Also a measure of program modularity vs these things. Modularity means how many cross module references a program has.

   \item Should the experimental results correspond to predictions made by a model?
 
   The model doesn't include optimizations, so no.

   \item Have appropriate baselines been identified?

   The baseline is the modular program before demodularization.

   \item What are the variables?

   Modularity, cpu caches, runtime startup.

   \item Are statistical methods necessary for validation?

   No, because any change in performance is significant, and we are not trying to show correlation.

   \end{enumerate}


   \subsection{Testing Methodology}

   Talk to stats people to make a good test
   
   \subsection{Results}

   Explain results and why they matter



\section{Related Work}
   \subsection{External Link-time Optimization}

   Explain efforts to do link time optimization in languages like C 
   
   \subsection{Cross-module Inlining}

   Explain difficulty of finding good heuristics. Matthias Blume on lambda splitting.

  

\section{Conclusion}

Demodularization is cool.

% We recommend abbrvnat bibliography style.

\bibliographystyle{abbrvnat}

% The bibliography should be embedded for final submission.

\begin{thebibliography}{}
\softraggedright

\bibitem[Smith et~al.(2009)Smith, Jones]{smith02}
P. Q. Smith, and X. Y. Jones. ...reference text...

\end{thebibliography}

\end{document}
